{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6064f73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#import libraries and the functions we defined\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from Networks import models\n",
    "from keras_unet.losses import jaccard_distance\n",
    "from keras_unet.metrics import dice_coef\n",
    "#from PCAUNetPP.losses import Hausdorff_distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from Data_Gen_2D import DataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "802c37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all metrics to evaluate model\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "smooth = 1\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_set(data_path, phrase):\n",
    "    set_of = [f for f in os.listdir(data_path) if phrase in f]\n",
    "    return np.array(set_of)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0158d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_predictions = r'D:\\Results_CK\\Compression\\Numpy\\PCA\\Kidneys\\npy'\n",
    "filepath_predictions = r'D:\\npy'\n",
    "filepath_tensors = r'D:\\t'\n",
    "filepath_data = r\"D:\\Data_128\\data\\\\\"\n",
    "\n",
    "images = gather_set(filepath_predictions, 'P')\n",
    "model_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb1b4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = list(set([os.path.basename(image)[:14] for image in images]))\n",
    "unique_ids = [name + '_' if not name.endswith('_') else name for name in unique_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b25c5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['186714_1_93_R_', '385151_1_140_R_', '385151_1_140_L_', '186714_3_96_R_', '457036_1_105_L_', '157925_1_141_R_', '383193_3_138_L_', '183417_1_144_R_', '113994_2_99_L_', '183417_0_129_R_', '290336_3_114_L_', '295106_0_108_R_', '186714_0_78_R_', '457036_0_105_R_', '186714_3_96_L_', '385151_3_154_R_', '295106_3_120_L_', '157925_0_126_R_', '290336_2_114_R_', '283935_1_135_R_', '187456_0_87_L_', '383193_6_147_L_', '385151_0_126_L_', '385151_2_147_L_', '113994_3_108_L_', '113994_1_99_L_', '187456_3_120_L_', '295106_1_108_L_', '295106_2_120_R_', '380166_4_144_R_', '457036_2_105_R_', '295106_0_108_L_', '139486_0_126_R_', '183417_3_144_R_', '283935_2_126_R_', '383193_4_117_L_', '385151_3_154_L_', '383193_5_129_L_', '139486_3_111_R_', '290336_1_114_L_', '457036_1_105_R_', '457036_3_111_L_', '186714_2_96_L_', '457036_2_105_L_', '383193_3_138_R_', '290336_2_114_L_', '380166_3_129_R_', '295106_3_120_R_', '283935_3_114_R_', '295106_2_120_L_', '385151_0_126_R_', '383193_4_117_R_', '157925_2_144_R_', '183417_2_144_R_', '157925_3_144_R_', '383193_6_147_R_', '187456_1_120_L_', '290336_0_120_R_', '385151_2_147_R_', '186714_1_93_L_', '457036_0_105_L_', '283935_0_135_R_', '186714_0_78_L_', '139486_2_99_R_', '290336_3_114_R_', '380166_1_120_R_', '139486_1_99_R_', '113994_0_87_L_', '457036_3_111_R_', '290336_0_120_L_', '295106_1_108_R_', '383193_5_129_R_', '380166_2_138_R_', '290336_1_114_R_', '187456_2_120_L_', '186714_2_96_R_']\n"
     ]
    }
   ],
   "source": [
    "print(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055505a",
   "metadata": {},
   "source": [
    "# Stack Images, ground truth and predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f538ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(unique_ids)):\n",
    "    pt_info = unique_ids[i]\n",
    "    pt_num, yr_num, num_slices = re.findall(r'\\d+', pt_info)\n",
    "    tensor = np.zeros((128,128,int(num_slices)))\n",
    "    for x in range(int(num_slices)):\n",
    "        img_name = unique_ids[i]+str(x)+'_C.npy'\n",
    "        image = np.load(filepath_data + '\\\\' + img_name)\n",
    "        img_slice = image\n",
    "        tensor[:,:,x] = img_slice\n",
    "        x = x+1\n",
    "    new_fname = unique_ids[i]+'C.npy'\n",
    "    np.save(os.path.join(filepath_tensors, new_fname), tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fe9d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(unique_ids)):\n",
    "    pt_info = unique_ids[i]\n",
    "    pt_num, yr_num, num_slices = re.findall(r'\\d+', pt_info)\n",
    "    tensor = np.zeros((128,128,int(num_slices)))\n",
    "    for x in range(int(num_slices)):\n",
    "        img_name = unique_ids[i]+str(x)+'_M.npy'\n",
    "        image = np.load(filepath_data + '\\\\' + img_name)\n",
    "        img_slice = image\n",
    "        tensor[:,:,x] = img_slice\n",
    "        x = x+1\n",
    "    new_fname = unique_ids[i]+'M.npy'\n",
    "    np.save(os.path.join(filepath_tensors, new_fname), tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5628fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unique_ids)):\n",
    "    pt_info = unique_ids[i]\n",
    "    pt_num, yr_num, num_slices = re.findall(r'\\d+', pt_info)\n",
    "    tensor = np.zeros((128,128,int(num_slices)))\n",
    "    for x in range(int(num_slices)):\n",
    "        img_name = unique_ids[i]+str(x)+ '_' + model_name +'_P.npy'\n",
    "        image = np.load(filepath_predictions + '\\\\' + img_name)\n",
    "        img_slice = image[:,:,1]\n",
    "        tensor[:,:,x] = img_slice\n",
    "        x = x+1\n",
    "    new_fname = unique_ids[i]+ model_name +'_Prediction.npy'\n",
    "    np.save(os.path.join(filepath_tensors, new_fname), tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19659c4",
   "metadata": {},
   "source": [
    "Gather prediction tensors and calculate stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bca7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['113994_0_87_L_test_Prediction.npy' '113994_1_99_L_test_Prediction.npy'\n",
      " '113994_2_99_L_test_Prediction.npy' '113994_3_108_L_test_Prediction.npy'\n",
      " '139486_0_126_R_test_Prediction.npy' '139486_1_99_R_test_Prediction.npy'\n",
      " '139486_2_99_R_test_Prediction.npy' '139486_3_111_R_test_Prediction.npy'\n",
      " '157925_0_126_R_test_Prediction.npy' '157925_1_141_R_test_Prediction.npy'\n",
      " '157925_2_144_R_test_Prediction.npy' '157925_3_144_R_test_Prediction.npy'\n",
      " '183417_0_129_R_test_Prediction.npy' '183417_1_144_R_test_Prediction.npy'\n",
      " '183417_2_144_R_test_Prediction.npy' '183417_3_144_R_test_Prediction.npy'\n",
      " '186714_0_78_L_test_Prediction.npy' '186714_0_78_R_test_Prediction.npy'\n",
      " '186714_1_93_L_test_Prediction.npy' '186714_1_93_R_test_Prediction.npy'\n",
      " '186714_2_96_L_test_Prediction.npy' '186714_2_96_R_test_Prediction.npy'\n",
      " '186714_3_96_L_test_Prediction.npy' '186714_3_96_R_test_Prediction.npy'\n",
      " '187456_0_87_L_test_Prediction.npy' '187456_1_120_L_test_Prediction.npy'\n",
      " '187456_2_120_L_test_Prediction.npy' '187456_3_120_L_test_Prediction.npy'\n",
      " '283935_0_135_R_test_Prediction.npy' '283935_1_135_R_test_Prediction.npy'\n",
      " '283935_2_126_R_test_Prediction.npy' '283935_3_114_R_test_Prediction.npy'\n",
      " '290336_0_120_L_test_Prediction.npy' '290336_0_120_R_test_Prediction.npy'\n",
      " '290336_1_114_L_test_Prediction.npy' '290336_1_114_R_test_Prediction.npy'\n",
      " '290336_2_114_L_test_Prediction.npy' '290336_2_114_R_test_Prediction.npy'\n",
      " '290336_3_114_L_test_Prediction.npy' '290336_3_114_R_test_Prediction.npy'\n",
      " '295106_0_108_L_test_Prediction.npy' '295106_0_108_R_test_Prediction.npy'\n",
      " '295106_1_108_L_test_Prediction.npy' '295106_1_108_R_test_Prediction.npy'\n",
      " '295106_2_120_L_test_Prediction.npy' '295106_2_120_R_test_Prediction.npy'\n",
      " '295106_3_120_L_test_Prediction.npy' '295106_3_120_R_test_Prediction.npy'\n",
      " '380166_1_120_R_test_Prediction.npy' '380166_2_138_R_test_Prediction.npy'\n",
      " '380166_3_129_R_test_Prediction.npy' '380166_4_144_R_test_Prediction.npy'\n",
      " '383193_3_138_L_test_Prediction.npy' '383193_3_138_R_test_Prediction.npy'\n",
      " '383193_4_117_L_test_Prediction.npy' '383193_4_117_R_test_Prediction.npy'\n",
      " '383193_5_129_L_test_Prediction.npy' '383193_5_129_R_test_Prediction.npy'\n",
      " '383193_6_147_L_test_Prediction.npy' '383193_6_147_R_test_Prediction.npy'\n",
      " '385151_0_126_L_test_Prediction.npy' '385151_0_126_R_test_Prediction.npy'\n",
      " '385151_1_140_L_test_Prediction.npy' '385151_1_140_R_test_Prediction.npy'\n",
      " '385151_2_147_L_test_Prediction.npy' '385151_2_147_R_test_Prediction.npy'\n",
      " '385151_3_154_L_test_Prediction.npy' '385151_3_154_R_test_Prediction.npy'\n",
      " '457036_0_105_L_test_Prediction.npy' '457036_0_105_R_test_Prediction.npy'\n",
      " '457036_1_105_L_test_Prediction.npy' '457036_1_105_R_test_Prediction.npy'\n",
      " '457036_2_105_L_test_Prediction.npy' '457036_2_105_R_test_Prediction.npy'\n",
      " '457036_3_111_L_test_Prediction.npy' '457036_3_111_R_test_Prediction.npy']\n",
      "['113994_0_87_L_C.npy' '113994_1_99_L_C.npy' '113994_2_99_L_C.npy'\n",
      " '113994_3_108_L_C.npy' '139486_0_126_R_C.npy' '139486_1_99_R_C.npy'\n",
      " '139486_2_99_R_C.npy' '139486_3_111_R_C.npy' '157925_0_126_R_C.npy'\n",
      " '157925_1_141_R_C.npy' '157925_2_144_R_C.npy' '157925_3_144_R_C.npy'\n",
      " '183417_0_129_R_C.npy' '183417_1_144_R_C.npy' '183417_2_144_R_C.npy'\n",
      " '183417_3_144_R_C.npy' '186714_0_78_L_C.npy' '186714_0_78_R_C.npy'\n",
      " '186714_1_93_L_C.npy' '186714_1_93_R_C.npy' '186714_2_96_L_C.npy'\n",
      " '186714_2_96_R_C.npy' '186714_3_96_L_C.npy' '186714_3_96_R_C.npy'\n",
      " '187456_0_87_L_C.npy' '187456_1_120_L_C.npy' '187456_2_120_L_C.npy'\n",
      " '187456_3_120_L_C.npy' '283935_0_135_R_C.npy' '283935_1_135_R_C.npy'\n",
      " '283935_2_126_R_C.npy' '283935_3_114_R_C.npy' '290336_0_120_L_C.npy'\n",
      " '290336_0_120_R_C.npy' '290336_1_114_L_C.npy' '290336_1_114_R_C.npy'\n",
      " '290336_2_114_L_C.npy' '290336_2_114_R_C.npy' '290336_3_114_L_C.npy'\n",
      " '290336_3_114_R_C.npy' '295106_0_108_L_C.npy' '295106_0_108_R_C.npy'\n",
      " '295106_1_108_L_C.npy' '295106_1_108_R_C.npy' '295106_2_120_L_C.npy'\n",
      " '295106_2_120_R_C.npy' '295106_3_120_L_C.npy' '295106_3_120_R_C.npy'\n",
      " '380166_1_120_R_C.npy' '380166_2_138_R_C.npy' '380166_3_129_R_C.npy'\n",
      " '380166_4_144_R_C.npy' '383193_3_138_L_C.npy' '383193_3_138_R_C.npy'\n",
      " '383193_4_117_L_C.npy' '383193_4_117_R_C.npy' '383193_5_129_L_C.npy'\n",
      " '383193_5_129_R_C.npy' '383193_6_147_L_C.npy' '383193_6_147_R_C.npy'\n",
      " '385151_0_126_L_C.npy' '385151_0_126_R_C.npy' '385151_1_140_L_C.npy'\n",
      " '385151_1_140_R_C.npy' '385151_2_147_L_C.npy' '385151_2_147_R_C.npy'\n",
      " '385151_3_154_L_C.npy' '385151_3_154_R_C.npy' '457036_0_105_L_C.npy'\n",
      " '457036_0_105_R_C.npy' '457036_1_105_L_C.npy' '457036_1_105_R_C.npy'\n",
      " '457036_2_105_L_C.npy' '457036_2_105_R_C.npy' '457036_3_111_L_C.npy'\n",
      " '457036_3_111_R_C.npy']\n"
     ]
    }
   ],
   "source": [
    "filepath_tensors = filepath_tensors\n",
    "pred_list = gather_set(filepath_tensors, '_Prediction')\n",
    "true_list = gather_set(filepath_tensors, '_C.')\n",
    "print(pred_list)\n",
    "print(true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39843b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Prediction.npy\n",
      "113994_0_87_L_tesC.npy\n"
     ]
    }
   ],
   "source": [
    "name =pred_list[0]\n",
    "print(name[18:46])\n",
    "test = pred_list[0][:17]+'C.npy'\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fce80b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results1 = []\n",
    "for i in range(len(pred_list)):\n",
    "    prediction = np.load(filepath_tensors + '\\\\'+ pred_list[i])\n",
    "    true = np.load(filepath_tensors + '\\\\'+true_list[i])\n",
    "    dice_calc = dice_coef(true,prediction)\n",
    "    #model = pred_list[i][:-6]\n",
    "    patient = pred_list[i][:-6]\n",
    "    new_calc = [dice_calc.numpy()]\n",
    "    new_calc1 = [patient, dice_calc.numpy()]\n",
    "    results.append(new_calc)\n",
    "    results1.append(new_calc1)\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6e7107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Dice Coefficient: 0.7170935117125993\n",
      "Minimum Dice Coefficient: 0.928668623125065\n",
      "Dice Coefficient Average: 0.8686934824283568\n",
      "Dice Coefficient Standard Deviation: 0.014869776147047653\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "min_values = []\n",
    "max_values = []\n",
    "for col in zip(*results):\n",
    "    col_values = [float(val()) if callable(val) else float(val) for val in col]\n",
    "    col_min = min(col_values)\n",
    "    col_max = max(col_values)\n",
    "    min_values.append(col_min)\n",
    "    max_values.append(col_max)\n",
    "\n",
    "# patient_min = min_values[0]  # Minimum value of patient values\n",
    "dice_calc_min = min_values[0]  # Minimum value of dice_calc values\n",
    "dice_calc_max = max_values[0]\n",
    "print(\"Minimum Dice Coefficient:\", dice_calc_min)\n",
    "print(\"Minimum Dice Coefficient:\", dice_calc_max)\n",
    "averages = []\n",
    "for col in zip(*results):\n",
    "    col_values = [float(val()) if callable(val) else float(val) for val in col]\n",
    "    col_avg = sum(col_values) / len(col_values)\n",
    "    averages.append(col_avg)\n",
    "dice_calc_avg = averages[0]\n",
    "# Calculate standard deviation for each parameter\n",
    "dice_calc_sd = math.sqrt(sum((float(val()) if callable(val) else float(val) - dice_calc_avg) ** 2 for val in results[0]) / len(results[0]))\n",
    "\n",
    "print(\"Dice Coefficient Average:\", dice_calc_avg)\n",
    "print(\"Dice Coefficient Standard Deviation:\", dice_calc_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba0e9e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['113994_0_87_L_tes', 0.8835635305066377], ['113994_1_99_L_tes', 0.8914922152092589], ['113994_2_99_L_tes', 0.8564934053918366], ['113994_3_108_L_te', 0.8934202600974314], ['139486_0_126_R_te', 0.9222143150392268], ['139486_1_99_R_tes', 0.9082955230969956], ['139486_2_99_R_tes', 0.9286691555879607], ['139486_3_111_R_te', 0.9129185161860741], ['157925_0_126_R_te', 0.8985464396452444], ['157925_1_141_R_te', 0.8952782078004687], ['157925_2_144_R_te', 0.883488930106251], ['157925_3_144_R_te', 0.9049351171785605], ['183417_0_129_R_te', 0.8453222321389027], ['183417_1_144_R_te', 0.8333218547638429], ['183417_2_144_R_te', 0.8695757761438256], ['183417_3_144_R_te', 0.8387048906656192], ['186714_0_78_L_tes', 0.889412605976103], ['186714_0_78_R_tes', 0.8963161398192137], ['186714_1_93_L_tes', 0.8939967145485421], ['186714_1_93_R_tes', 0.8807512055201604], ['186714_2_96_L_tes', 0.8964511230274046], ['186714_2_96_R_tes', 0.8918503689453008], ['186714_3_96_L_tes', 0.9014284297581412], ['186714_3_96_R_tes', 0.8914066553884591], ['187456_0_87_L_tes', 0.8376125386741038], ['187456_1_120_L_te', 0.7834111488702303], ['187456_2_120_L_te', 0.8719975252670579], ['187456_3_120_L_te', 0.8396779235741831], ['283935_0_135_R_te', 0.782456300694144], ['283935_1_135_R_te', 0.9224293062014783], ['283935_2_126_R_te', 0.7170911575193176], ['283935_3_114_R_te', 0.8617708426035608], ['290336_0_120_L_te', 0.7646300321714062], ['290336_0_120_R_te', 0.7188860428715725], ['290336_1_114_L_te', 0.8997311990897863], ['290336_1_114_R_te', 0.8896434314483053], ['290336_2_114_L_te', 0.9073077231661594], ['290336_2_114_R_te', 0.9094306681802574], ['290336_3_114_L_te', 0.8893333276715658], ['290336_3_114_R_te', 0.9112972888842823], ['295106_0_108_L_te', 0.8084483629102212], ['295106_0_108_R_te', 0.8695431507571169], ['295106_1_108_L_te', 0.8677910157975467], ['295106_1_108_R_te', 0.8966799484708411], ['295106_2_120_L_te', 0.8851080247278349], ['295106_2_120_R_te', 0.9155883593320022], ['295106_3_120_L_te', 0.8768011106839891], ['295106_3_120_R_te', 0.8727277278083178], ['380166_1_120_R_te', 0.8857415407858813], ['380166_2_138_R_te', 0.9002967839231022], ['380166_3_129_R_te', 0.8551380743002045], ['380166_4_144_R_te', 0.8730019063765139], ['383193_3_138_L_te', 0.9002087444986941], ['383193_3_138_R_te', 0.8578343993069848], ['383193_4_117_L_te', 0.8227963960870961], ['383193_4_117_R_te', 0.813126070945089], ['383193_5_129_L_te', 0.8678464186969796], ['383193_5_129_R_te', 0.8312025603960245], ['383193_6_147_L_te', 0.879085154072917], ['383193_6_147_R_te', 0.8078333488152196], ['385151_0_126_L_te', 0.817700647750293], ['385151_0_126_R_te', 0.9022738146969455], ['385151_1_140_L_te', 0.7410221146157093], ['385151_1_140_R_te', 0.8763035684454551], ['385151_2_147_L_te', 0.8559966797123962], ['385151_2_147_R_te', 0.8867411016275605], ['385151_3_154_L_te', 0.8530546273024133], ['385151_3_154_R_te', 0.885968506140881], ['457036_0_105_L_te', 0.9058489198449781], ['457036_0_105_R_te', 0.8995017600377094], ['457036_1_105_L_te', 0.8513308770787534], ['457036_1_105_R_te', 0.9038080535029303], ['457036_2_105_L_te', 0.8764424354180439], ['457036_2_105_R_te', 0.8988347465396909], ['457036_3_111_L_te', 0.8917080484556974], ['457036_3_111_R_te', 0.8727960802797787]]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e273351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results1)\n",
    "df.columns =[ 'Patient','Dice']\n",
    "filepath = r\"D:\\Results_CK\\sUNet++\\Cyst\\performance.xlsx\"\n",
    "df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68843c47",
   "metadata": {},
   "source": [
    "# Convert predictions to nii for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5346148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_images(data_path):\n",
    "    images = []\n",
    "    path = data_path + '\\\\'\n",
    "    for f in os.listdir(data_path):\n",
    "      if '_test' in f:\n",
    "        images.append(f)\n",
    "        \n",
    "      else:\n",
    "        continue\n",
    "    images = np.array(images)\n",
    "    #segmentations = np.array(segmentations)\n",
    "\n",
    "    indices = np.array(range(len(images))) # we will use this in the next step.\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef9a47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "filepath_tensors = r'D:\\t'\n",
    "images = gather_images(filepath_tensors)\n",
    "print(len(images))\n",
    "path = r'D:\\Results_CK\\sUNet++\\Cyst\\nii'\n",
    "for i in range(len(images)):\n",
    "    image = np.load(os.path.join(filepath_tensors, images[i]))\n",
    "    affine = np.eye(4)\n",
    "    nifti_file = nib.Nifti1Image(image, affine)\n",
    "    filename = images[i][:-3]+'nii'\n",
    "    nib.save(nifti_file, os.path.join(path, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
