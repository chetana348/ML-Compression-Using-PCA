{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed3c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import keras\n",
    "from keras_unet_collection import models\n",
    "import keras_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9d38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define custom objects\n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (\n",
    "                K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(self, y_true, y_pred):\n",
    "    loss = 1 - self._dice_coef(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "class GELU(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GELU, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return keras.activations.gelu(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11f95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = keras.models.load_model(r\"C:\\Users\\UAB\\Segmentation - Main1_CK\\Human Model\\Keras\\runet_kid_best_train.h5\", custom_objects={\n",
    "                       'jaccard_distance': jaccard_distance,\n",
    "                       'dice_coef_loss': dice_coef_loss,\n",
    "                       'dice_coef': dice_coef}) #load the weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "297e743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "# Flatten the weights into a 2D matrix\n",
    "flattened_weights = np.concatenate([w.flatten() for w in weights])\n",
    "flattened_weights = flattened_weights.reshape(-1, 1)\n",
    "\n",
    "# Perform PCA on the weight matrix\n",
    "pca = PCA()\n",
    "pca.fit(flattened_weights)\n",
    "\n",
    "# Select a subset of the principal components based on the desired compression ratio\n",
    "compression_ratio = 0.5  # Example compression ratio of 50%\n",
    "num_components = int(len(flattened_weights) * compression_ratio)\n",
    "selected_components = pca.components_[:num_components]\n",
    "\n",
    "# Reconstruct the compressed weights using the selected principal components\n",
    "compressed_weights = np.dot(selected_components, pca.transform(flattened_weights).T).T\n",
    "\n",
    "# Update the model with the compressed weights\n",
    "start_index = 0\n",
    "for i in range(len(weights)):\n",
    "    shape = weights[i].shape\n",
    "    size = np.prod(shape)\n",
    "    end_index = start_index + size\n",
    "    weights[i] = compressed_weights[start_index:end_index].reshape(shape)\n",
    "    start_index = end_index\n",
    "\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f89b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the magnitude of each weight\n",
    "weight_magnitudes = []\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'get_weights'):\n",
    "        weights = layer.get_weights()\n",
    "        for weight in weights:\n",
    "            weight_magnitudes.append(np.abs(weight).flatten())\n",
    "\n",
    "# Concatenate the weight magnitudes into a single array\n",
    "weight_magnitudes = np.concatenate(weight_magnitudes)\n",
    "\n",
    "# Normalize the magnitudes\n",
    "weight_magnitudes /= np.sum(weight_magnitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b23df62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_ratio = 0.5  # Example pruning ratio of 50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44d10460",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(weight_magnitudes)[::-1]\n",
    "threshold_index = int(len(sorted_indices) * pruning_ratio)\n",
    "threshold = weight_magnitudes[sorted_indices[threshold_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a601c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "# Define the pruning schedule\n",
    "pruning_schedule = sparsity.ConstantSparsity(target_sparsity=pruning_ratio, begin_step=0, end_step=-1, frequency=100)\n",
    "\n",
    "# Apply pruning to the model\n",
    "pruned_model = sparsity.prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n",
    "\n",
    "# Prune the model by applying the threshold to each weight\n",
    "for layer in pruned_model.layers:\n",
    "    if hasattr(layer, 'get_prunable_weights'):\n",
    "        prunable_weights = layer.get_prunable_weights()\n",
    "        pruned_weights = []\n",
    "        for weight in prunable_weights:\n",
    "            pruned_weight = np.where(np.abs(weight) < threshold, 0.0, weight)\n",
    "            pruned_weights.append(pruned_weight)\n",
    "        layer.set_weights(pruned_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1950cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = sparsity.strip_pruning(pruned_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3038216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
